{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install transformers torch huggingface_hub > /dev/null\n",
    "! pip install torch torchvision > /dev/null\n",
    "! pip install transformers datasets \n",
    "! pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd12b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# df=pd.read_csv(\"fol_expressions_20000.csv\")\n",
    "# column_titles=['english_description','expression']\n",
    "# df=df.reindex(columns=column_titles)\n",
    "# df.to_csv('fol_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1871010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "TOKENIZERS_PARALLELISM = os.getenv(\"TOKENIZERS_PARALLELISM\")\n",
    "from huggingface_hub import login\n",
    "login(token = TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ee01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-1b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578817c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "dataset = load_dataset('csv', data_files = \"fol_dataset.csv\")['train']\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_set = split_dataset['train']\n",
    "test_set = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511df0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "     inputs = tokenizer(\n",
    "         batch['expression'],\n",
    "         max_length=128,\n",
    "         truncation=True,\n",
    "         padding = 'max_length',\n",
    "         \n",
    "     )    \n",
    "    \n",
    "     labels = tokenizer(\n",
    "         batch['english_description'],\n",
    "         max_length =128,\n",
    "         truncation = True, \n",
    "         padding = 'max_length'\n",
    "     )\n",
    "     inputs['labels']=labels['input_ids']\n",
    "     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = train_set.map(preprocess, batched=True)\n",
    "test_tokenized = test_set.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1069d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the trainer \n",
    "from transformers import Trainer, TrainingArguments \n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
